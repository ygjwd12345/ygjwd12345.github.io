
<!-- saved from url=(0025)http://ygjwd12345.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <title>Guanglei Yang</title>
  <meta content="Guanglei Yang, ygjwd12345.github.io" name="keywords">
  <style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
a {
  color: #1772d0;
  text-decoration:none;
}
a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}
a.paper {
  font-weight: bold;
  font-size: 12pt;
}
b.paper {
  font-weight: bold;
  font-size: 12pt;
}
* {
  margin: 0pt;
  padding: 0pt;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 900px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15px;
  background: #eee;
}
h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16pt;
  font-weight: 700;
}
h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 17px;
  font-weight: 700;
  padding-bottom: 0.5em;
}
strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  font-weight:bold;
}
ul { 
  list-style: circle;
}
img {
  border: none;
}
li {
  padding-bottom: 0.6em;
  margin-left: 1.4em;
}
alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight: bold;
  color: #FF0000;
}
em, i {
  font-style:italic;
}
div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}
div.spanner {
  clear: both;
}
div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}
div.paper div {
  padding-left: 230px;
}
img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}
span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}
pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}
div.paper pre {
  font-size: 0.9em;
}

.paper-title {
    color: #003399;
    font-weight: 500;
}
</style>

<link href="./index_files/css" rel="stylesheet" type="text/css"><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
<script async="" src="http://www.google-analytics.com/analytics.js"></script><script async="" src="http://www.google-analytics.com/analytics.js"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-45959174-3', 'ygjwd12345.github.io');
  ga('send', 'pageview');
</script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');
</script><script type="text/javascript" src="./index_files/jquery-1.12.4.min.js"></script></head>


<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
<div style="margin: 0px auto; width: 100%;">
<img title="Guanglei Yang" style="float: left; padding-left: .01em; height: 140px;" src="./index_files/guangleiyang.jpg">
<div style="padding-left: 12em; vertical-align: top; height: 120px;"><span style="line-height: 150%; font-size: 20pt;">Guanglei Yang</span><br>
<span><strong>PhD student</strong></span><br>
<span>School of Instumentation Science and Engineering </span><br>
<span>Harbin Institude of Technology, China</span><br>
<span><strong>Address</strong>: 92 Xidazhi Street, Nangang District, Harbin City, Heilongjiang Province, China </span><br>
<span><strong>Email  </strong>: yangguanglei [at] hit.edu.cn</span> &nbsp &nbsp
<a href="https://github.com/ygjwd12345">Github</a>  &nbsp &nbsp
<a href="https://scholar.google.com/citations?user=DHgNKnAAAAAJ&hl=en">Google Scholar</a></span><br>
</span></div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<div style="clear: both;">
<div class="section">
<h2>Biography (<a href="http://ygjwd12345.github.io/index_files/cv.pdf">CV</a>)</h2>
<div class="paper">
  Guanglei Yang currently studies at School of Instumentation Science and Engineering, Harbin Institude of Technology, China.
He was also visiting student (2020.01-2022.02) in
<a href="http://mhug.disi.unitn.it/">Multimedia and Human Understanding Group (MHUG) </a>
at the Department of Information Engineering and Computer Science,
University of Trento, Italy , supervised by Prof. <a href="https://scholar.google.ca/citations?user=xf1T870AAAAJ&hl=en">Elisa Ricci</a>.
His interests are <b>deep representation learning</b>, <b>attention mechanism</b>, <b>domain adaptation</b> and <b>Transformer's
applications to Autonomous Driving</b>.
</div>
</div>
</div>

<div style="clear: both;">
<div class="section">
  <h2>News</h2>
  <div class="paper">
  <ul>
  <li> 6/2021: One paper was accepted to ICCV.
  <li> 2/2020: One paper was accepted to AAAI.
  </ul>
  </div>
</div>
</div>


<div style="clear: both;">
<div class="section">
  <h2>Research Experience</h2>
  <div class="paper">
  <ul> 
    <li><b>MHUG</b>, Trento, Italy. 1/2020-2/2022 <br>
      Mentors: Prof. <a href="https://scholar.google.ca/citations?user=xf1T870AAAAJ&hl=en">Elisa Ricci</a> and Dr. <a href="https://scholar.google.com/citations?user=9zJkeEMAAAAJ&hl=en">Hao Tang</a>. <br>
      Transformer,deep representation learning and domain <adaptation></adaptation>. </li>
  </ul>
  </div>
</div>
</div>

<div style="clear: both;">
<div class="section">
  <h2>Publications</h2>

  <h3 id="confpapers">&#10022 <i>Conferences</i></h3>  
  
  <div class="paper">
  <ul>
    <li>
      <img title="semantic-guided" style="float: right; padding-right: .01em; width: 300px;" src="./figures/iccv2021.jpg">
      <span class="paper-title">Transformer-Based Attention Networks for Continuous Pixel-Wise Prediction</span>. <br>
      <b>Guanglei Yang</b>, Hao Tang, Mingli Ding, Nicu Sebe, Elisa Ricci <br>
      <i>to appear in IEEE International Conference on Computer Vision </i>(<b>ICCV</b>), 2021. <br>
      <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Yang_Transformer-Based_Attention_Networks_for_Continuous_Pixel-Wise_Prediction_ICCV_2021_paper.pdf">[paper]</a><a href="https://arxiv.org/abs/2103.12091">[arXiv]</a><a href="https://github.com/ygjwd12345/TransDepth">[code]</a>
    </li>
  </ul>


  <ul>
    <li>
      <span class="paper-title">Bi-Directional Generation for Unsupervised Domain Adaptation</span>. <br>
      <b>Guanglei Yang</b>, Haifeng Xia, Mingli Ding, Zhengming Ding<br>
      <i>to appear in Proceedings of the AAAI Conference on Artificial Intelligence</i>(<b>AAAI</b>), 2020. <br>
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/6137/5993">[paper]</a>
    </li>
  </ul>
  </div>

  <h3 id="confpapers">&#10022 <i>Journals</i></h3>

  <div class="paper">
  <ul>
    <li>
      <span class="paper-title">Bi-directional class-wise adversaries for unsupervised domain adaptation</span>. <br>
      <b>Guanglei Yang</b>, Mingli Ding, Yongqiang Zhang, <br>
      <b>Applied Intelligence</b>, Page(s): 1--17, 2021. (Impact factor: 5.086).
      <a href="https://link.springer.com/content/pdf/10.1007/s10489-021-02609-7.pdf">[paper]</a>
    </li>
  </ul>
  </div>
  
  
  <h3 id="confpapers">&#10022 <i>Preprint</i></h3>
  <div class="paper">
  <ul>
  <li>
    <span class="paper-title">Bi-Mix: Bidirectional Mixing for Domain Adaptive Nighttime Semantic Segmentation</span>. 2021. <br>
    <b>Guanglei Yang</b>, Zhun Zhong, Hao Tang,  Mingli Ding, Nicu Sebe, Elisa Ricci.
    <a href="https://arxiv.org/abs/2111.10339">[arXiv]</a><a href="https://github.com/ygjwd12345/BiMix">[code]</a>
  </li>
  <li>
    <span class="paper-title">Global and Local Alignment Networks for Unpaired Image-to-Image Translation</span>. 2021. <br>
    <b>Guanglei Yang</b>, Hao Tang, Humphrey Shi, Mingli Ding, Nicu Sebe, Radu Timofte, Luc Van Gool, Elisa Ricci
    <a href="https://arxiv.org/abs/2111.10346">[arXiv]</a><a href="https://github.com/ygjwd12345/GLANet">[code]</a>
  </li>
  <li>
    <span class="paper-title">Transformer-Based Source-Free Domain Adaptation</span>. 2021. <br>
    <b>Guanglei Yang</b>, Hao Tang, Zhun Zhong, Mingli Ding, Nicu Sebe, Elisa Ricci.
    <a href="https://arxiv.org/pdf/2105.14138.pdf">[arXiv]</a><a href="https://github.com/ygjwd12345/TransDA">[code]</a>
  </li>

  <li>
    <span class="paper-title">Variational Structured Attention Networks for Deep Visual Representation Learning</span>. 2021. <br>
    <b>Guanglei Yang</b>, Paolo Rota, Xavier Alameda-Pineda,Dan Xu, Mingli Ding, Elisa Ricci.
    <a href="https://arxiv.org/pdf/2103.03510.pdf">[arXiv]</a><a href="https://github.com/ygjwd12345/VISTA-Net">[code]</a>
  </li>
  </ul>  
  </div>
</div>
</div>



<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Professional Activities</h2>
<div class="paper">
  <h3>Conference reviewer/TPC member</h3>
  <ul>
    <li> IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR 2022</b>) </li>
    <li> IEEE/CVF International Conference on Computer Vision (<b>ICCV 2021</b>) </li>
    <li> IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR 2021</b>) </li>
    <li> The 28th ACM International Conference on Multimedia (<b>ACM MM 2020</b>) </li>
  </ul>
</div>
</div>
</div>




<div style="clear:both;">
<p align="right"><font size="5">Last Updated on 23 Novenber, 2021</font></p>
<p align="right"><font size="5">Published with <a href="https://pages.github.com/">GitHub Pages</a></font></p>
</div>

<div class="jvectormap-tip"></div></body></html>
